\documentclass[russian,a4paper,12pt]{article}
\usepackage[utf8]{inputenc}
\usepackage[russian]{babel}
\usepackage{url}
\usepackage{fullpage}
\usepackage{comment}

\sloppy
\hyphenpenalty=666

\begin{document}
\title{RELZ4~--- ускоренный\\алгоритм разжатия}
\author{Алексей Турбин}
\date{1 июля 2021 г.}
\maketitle

\begin{abstract}
Рассмотрены модификации алгоритма сжатия LZ4, которые обеспечивают ускоренное разжатие.
Ускорение достигает $1.4\times$.
\end{abstract}

\section{Введение}
LZ4~--- быстрый алгоритм сжатия, не использующий энтропийного кодирования.
Сжатый поток имеет байтовую структуру, которую в упрощенном виде можно представить так:
\begin{verbatim}
    [T|LLL|MO] [T|LLL|MO] ... [T|LLL]
\end{verbatim}
Квадратные скобки показывают \emph{последовательность} (sequence) из двух операций:
копирование \emph{литералов} и копирование \emph{совпадения} (match).  Первый
байт последовательности \verb|T|~--- это \emph{токен}, в котором два 4-битных поля:
количество литералов \verb|T>>4| и длина совпадения \verb|4+(T&15)| (мин.~длина 4).
Признак \verb|(T>>4)==15| указывает на то, что литералов может быть больше 15,
тогда считывается дополнительный \emph{байт кодирования длины} (между \verb|T|
и \verb|LLL|, не показан; аналогично может быть увеличена длина совпадения).
Литералы \verb|LLL| (переменное количество) копируются из сжатого потока в выходной поток.
После этого копируется совпадение. Два байта \verb|MO| (match offset) указывают
\emph{смещение назад} (относительно текущего указателя в выходном потоке),
по которому находится совпадение.  Самая последняя последовательность не полная,
копируются только литералы.

Далее обсуждаются некоторые модификации, приводящие к увеличению скорости копирования.

\section{Минимальное смещение}
Когда копируется совпадение по маленькому смещению \verb|MO|, участки памяти
могут перекрываться.  В таком случае нельзя использовать обычный цикл копирования,
похожий на \verb|memcpy|, потому что копирование имеет побайтовую семантику
(например, копирование по смещению 1 реплицирует последний байт).
В LZ4 выполняется проверка \verb|MO<16| (или \verb|MO<8|): в таком случае
совпадение нельзя копировать при помощи SIMD-регистра (соотв.~64-битного
регистра), а требуется сложная процедура репликации начального участка.
В \cite{yandex2019} показано, что такая репликация может быть выполнена
с помощью SIMD-инструкции перестановки байтов \verb|pshufb|.

Однако можно просто не связываться со слишком маленькими смещениями, а использовать
смещение \verb|MO+C|, где \verb|C=8| или \verb|C=16|.  Наши эксперименты показывают,
что при \verb|C=8| потери в сжатии составляют около 0.1\%, а при \verb|C=16|~--- еще 0.3\%.
Такие потери почти всегда приемлемы.  Но здесь нужно быть осторожным: низкие
потери обусловлены использованием медленного алгоритма сжатия LZ4HC, который перебирает
несколько совпадений (в поисках более длинного).  А быстрый алгоритм сжатия просто отбросит
единственное имеющееся совпадение из-за короткого смещения, так что потери в сжатии могут быть выше.

Настало время уточнить, что же бы оптимизируем.  Мы оптимизируем скорость
распаковки исходя из того, что данные сжимаются для долгосрочного хранения сравнительно медленным алгоритмом,
а разжиматься будут многократно.  Существует и другой сценарий: данные сжимаются, передаются
и разжимаются только один раз.  В таком случае бесполезно оптимизировать разжатие, а нужно оптимизировать
сжатие, поскольку даже быстрое сжатие в разы медленнее разжатия.

\section{Кодирование длин}
Когда \verb|(T>>4)==15| (или когда \verb|4+(T&15)==4+15|), считывается дополнительный байт кодирования длины
литералов (соотв.~совпадения).  Если этот байт равен 255, то считывается еще один байт, и т.\,д.
Такая система неэффективна: длина $n$ кодируется $O(n)$ байтами.  Вместо это можно было бы использовать
кодировку VByte, в которой старший бит служит признаком продолжения.  Длина кода будет
$O(\log{}n)$, но длины 128-254 будут кодироваться двумя байтами.

В LZ4 байт длины имеет одно специальное значение, а в VByte половина всех значений специальные.
Наилучший результат получается, когда специальных значений меньше половины.
Для первого байта мы выделяем 16 специальных значений, так что распаковка длины начинается так:
\begin{verbatim}
    len = *src++;
    if (len >= 256-16)
        len += 16 * *src++;
\end{verbatim}
Для второго байта мы оставляем 32 специальных значения.  Теперь длины 128-239 требуют одного байта,
а два байта кодируют длины до 3823.

В LZ4 длины не ограничены, но алгоритмы сжатия ограничивает общий размер \verb|LZ4_MAX_INPUT_SIZE| менее 2 Гб.
В нашей модификации длины ограничены~--- чуть менее 4 Гб.

\section{Длина совпадения 19}
При кодировании совпадении с длиной \verb|4+15| компрессор записывает дополнительный байт длины, равный 0.
Это хуже, чем записать совпадение длиной 18 и оставить последний байт для следующей последовательности.
В худшем случае последний байт станет литералом в следующей последовательности, но при распаковке не придется
считывать байт длины (который даст нарушение предсказания перехода).  В лучшем же случае это байт
станет частью нового совпадения.

В нашей модификации вообще исключена возможность кодирования длины совпадения 19: к длинам с дополнительным
байтами прибавляется 20.

\section{Конвейеризация}
Посмотрим еще раз на последовательность \verb![T|LLL|MO]!.  Чтобы прочитать смещение \verb|MO|,
нужно сначала узнать количество литералов \verb|LLL|.  Из-за такого рода зависимости по данным
процессор не может начать обработку совпадения параллельно с обработкой литералов.  Можно было бы
фиксировать расположение смещения: \verb![T|MO|LLL]!.  Но в наших экспериментах это не приводит
к увеличению скорости распаковки.  Вместо это мы обнаружили, что основным препятствием является
считывание токена в начале каждой итерации.  Желательно, чтобы к началу следующей итерации токен
был уже загружен и частично обработан.  Это требует изменения формата сжатого потока, который
теперь выглядит так:
\begin{verbatim}
    [T] [T|LLL|MO] [T|LLL|MO] ... [T|LLL]
\end{verbatim}
Здесь \verb![T]! является \emph{сигнальным токеном}, а внутри последовательности кодируется
\emph{следующий токен}.  Такая техника оптимизации называется \emph{программная конвейеризация}
(software pipelining).  Последний токен реинтерпретируется как литерал.

\section{Скорость разжатия}
Для оценки скорости мы используем программу \verb|lzbench| на микроархитектуре Haswell.
Скорость распаковки LZ4 на корпусе Silesia~--- около 2.6 Гб/c, нашей модификации~--- 3.6 Гб/с
(скорость \verb|memcpy|~--- 8 Гб/c, память DDR3).  В обоих случаях используются похожие алгоритмы медленного сжатия.
\begin{verbatim}
lzbench 1.8 (64-bit Linux)  Intel(R) Celeron(R) CPU G1840 @ 2.80GHz
Assembled by P.Skibinski

Compressor name   Compress. Decompress. Compr. size  Ratio Filename
memcpy             8077 MB/s  7968 MB/s   211938580 100.00 12 files
lz4hc 1.9.3 -7       31 MB/s  2677 MB/s    78102177  36.85 12 files
relz4 0.1            28 MB/s  3668 MB/s    78126076  36.86 12 files
\end{verbatim}

\begin{thebibliography}{9}
\bibitem[Яндекс 2019]{yandex2019} Алексей Миловидов.
Как ускорить разжатие LZ4 в ClickHouse.
Блог компании Яндекс, 21 мая 2019.
\url{https://habr.com/ru/company/yandex/blog/452778/}
\end{thebibliography}

\end{document}
